{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e615970-2027-4fde-8f5a-740c4ce3eff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 12:04:03.930492: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 12:04:04.283387: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-20 12:04:04.283421: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-20 12:04:05.490018: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-20 12:04:05.490096: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-20 12:04:05.490103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f09ab98-06eb-475f-9fe5-f9f666ac6b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased-distilled-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc2cafe-5957-4619-adc4-9b10a414916d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelqa = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae185fd1-fc63-4453-b835-8b83d22231f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"joeddav/xlm-roberta-large-xnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9144e447-ea45-4ece-89c3-2d582bcd14ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def findAction(sentence,candidate_labels = [\"Take\", \"Drop\", \"Perform an action\"]):\n",
    "    result=classifier(sentence, candidate_labels)\n",
    "    action=result['labels']\n",
    "    score=result['scores']\n",
    "    index=action.index(\"Perform an action\")\n",
    "    action.remove(\"Perform an action\")\n",
    "    score.pop(index)\n",
    "    return action,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add248d1-d87a-4126-ae45-9039081eb900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  (['Take', 'Drop'], [0.14090073108673096, 0.02239922806620598])\n"
     ]
    }
   ],
   "source": [
    "result=findAction(\"Next to the crate there is a yellow cube that you must grab.\")\n",
    "print(\"result: \",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a768c71d-bd60-4fc4-ac89-a2cbc4e79cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def findTarget(text,action):\n",
    "    if action==\"Take\":\n",
    "        question=\"What should be taken?\"\n",
    "    else:\n",
    "        question=\"Where should we drop the object?\"\n",
    "    inputs = tokenizer(question, text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = modelqa(**inputs)\n",
    "    answer_start_index = torch.argmax(outputs.start_logits)\n",
    "    answer_end_index = torch.argmax(outputs.end_logits)\n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    return tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba570c31-0308-4c09-80e4-3e66f9ec5186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a yellow cube'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findTarget(\"Next to the crate there is a yellow cube that you must grab.\",\"Take\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e4e14",
   "metadata": {},
   "source": [
    "Pour les réponses à des questions plus complexes le modèle DistillBert semble insuffisant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55e9b5bc-8074-4fb1-b504-81ad9646eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askQuestion(text,question):\n",
    "    inputs = tokenizer(question, text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = modelqa(**inputs)\n",
    "    answer_start_index = torch.argmax(outputs.start_logits)\n",
    "    answer_end_index = torch.argmax(outputs.end_logits)\n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    return tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eac43f",
   "metadata": {},
   "source": [
    "On voit qu'il répond mal même dans des cas très simples comme ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "771e5695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'take the cube. then you must put it in the casse'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askQuestion('Context: the cube is taken. Order: \"Take the cube. Then you must put it in the casse\"', \"What should I do now?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea6f1cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you must put it in the casse'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askQuestion('Context: the cube is taken. Order: \"Take the cube, Then you must put it in the casse\"', \"What should I do now?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8eb5f46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a cube and a sphere'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askQuestion('Each box must contain a cube and a sphere.', 'What object is the container?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da7a81",
   "metadata": {},
   "source": [
    "Le modèle Roberta finetunner pour le SQAD semble plus adapté:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5800832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0233d26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'put it in the casse'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_input = {\n",
    "    'question': \"What should I do now?\",\n",
    "    'context': 'Context: the cube is taken. Order: \"Take the cube. Then you must put it in the casse\"'\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "res['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41a8f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askQuestion(text,question):\n",
    "    QA_input = {\n",
    "        'question': question,\n",
    "        'context': text\n",
    "    }\n",
    "    res = nlp(QA_input)\n",
    "    return res['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1f3b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askAction(state,order,question=\"What should I do now?\"):\n",
    "    QA_input = {\n",
    "        'question': question,\n",
    "        'context': 'Context: '+state+ 'Order: '+order\n",
    "    }\n",
    "    res = nlp(QA_input)\n",
    "    return res['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff74dbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'put it in the casse'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askQuestion('Context: the cube is taken. Order: \"Take the cube, Then you must put it in the casse\"', \"What should I do now?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5cf3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
